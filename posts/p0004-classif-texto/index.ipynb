{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"AI na Análise de Dados - Classificação de Texto com a API da OpenAI\"\n",
    "author: \"Walter R. Paixão-Côrtes\"\n",
    "date: \"2023-06-16\"\n",
    "categories: [OpenAI API]\n",
    "image: nlp-text-classif.png\n",
    "toc: true\n",
    "description: Vamos utilizar a API da OpenAI para executar uma das tarefas mais comuns em NLP - a classificação de textos.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olá, tudo bem?\n",
    "\n",
    "A esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\n",
    "\n",
    "Este será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação de dados é uma tarefa de aprendizado supervisionado que envolve a categorização de uma determinada amostra de dados em uma das várias classes predefinidas. Cada amostra é atribuída a uma e somente uma classe, baseando-se nas características dessa amostra.\n",
    "\n",
    "Por exemplo, imagine que você tem um conjunto de emails e você quer classificá-los como \"spam\" ou \"não spam\". Nesse caso, \"spam\" e \"não spam\" são as classes, e cada email é uma amostra que será classificada em uma dessas classes.\n",
    "\n",
    "A classificação é geralmente realizada utilizando algoritmos de aprendizado de máquina. Esses algoritmos aprendem a classificar novas amostras baseando-se em um conjunto de treinamento. O conjunto de treinamento é um conjunto de amostras para as quais as classes verdadeiras são conhecidas.\n",
    "\n",
    "Os algoritmos de classificação incluem árvores de decisão, regressão logística, máquinas de vetores de suporte, redes neurais e muitos outros. A escolha do algoritmo depende de vários fatores, como a natureza dos dados, o número de classes, a necessidade de interpretabilidade e outros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mas e se não temos conjuntos de dados de treinamento?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você não tem um conjunto de dados de treinamento rotulado, ainda existem várias abordagens que você pode usar, tais como:\n",
    "\n",
    "1. **Aprendizado não supervisionado**\n",
    "2. **Aprendizado semi-supervisionado**\n",
    "3. **Aprendizado por reforço**\n",
    "4. **Rotulagem manual**\n",
    "5. **Geração de rótulos sintéticos**\n",
    "6. **Processamento de Linguagem Natural**\n",
    "\n",
    "E é nesta última opção que podemos utilizar o GPT para nos ajudar, pois o modelo do GPT é gigantesco, tendo sido treinado com conteúdo de toda a internet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT versus métodos mais tradicionais de classificação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos de linguagem como o GPT (Generative Pretrained Transformer) têm várias vantagens e desvantagens, especialmente quando comparados a outros métodos de análise de texto. Aqui estão algumas delas:\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "1. **Compreensão Profunda da Linguagem**: O GPT é treinado em enormes quantidades de texto, o que lhe permite aprender uma rica compreensão da linguagem natural. Isso inclui uma compreensão de sintaxe, semântica, e até mesmo alguns elementos de conhecimento do mundo real.\n",
    "\n",
    "2. **Versatilidade**: O GPT pode ser usado para uma ampla gama de tarefas de processamento de linguagem natural, incluindo tradução de texto, geração de texto, resumo de texto, análise de sentimento, resposta a perguntas e muito mais.\n",
    "\n",
    "3. **Aprendizado Transferível**: O GPT utiliza o aprendizado transferível, o que significa que o conhecimento aprendido durante o treinamento em um grande conjunto de dados pode ser aplicado a tarefas específicas com relativamente poucos dados de treinamento adicionais. Isso permite ao GPT se adaptar a uma ampla gama de tarefas com um desempenho impressionante.\n",
    "\n",
    "4. **Modelagem de Contexto**: A arquitetura do Transformer, utilizada pelo GPT, é especialmente boa para entender o contexto em uma sequência de texto, o que é crucial para muitas tarefas de processamento de linguagem natural.\n",
    "\n",
    "**Desvantagens:**\n",
    "\n",
    "1. **Necessidade de Grandes Quantidades de Dados de Treinamento**: O GPT precisa de grandes quantidades de dados de treinamento para aprender efetivamente. Isso pode tornar o treinamento do modelo do zero proibitivamente caro em termos de tempo e recursos computacionais.\n",
    "\n",
    "2. **Dificuldade de Interpretação**: O GPT, como muitos modelos de aprendizado profundo, pode ser difícil de interpretar. Ele pode produzir resultados impressionantes, mas pode ser difícil entender por que fez uma determinada previsão.\n",
    "\n",
    "3. **Sensibilidade ao Ruído e Erros**: Embora o GPT seja robusto em muitos aspectos, ele pode ser sensível a ruído e erros no texto de entrada. Pequenas mudanças no texto de entrada podem às vezes levar a grandes mudanças nas previsões do modelo.\n",
    "\n",
    "4. **Potencial de Viés**: O GPT aprende com os dados em que é treinado, e se esses dados contêm viés, o modelo também pode exibir viés. Isso pode ser um problema significativo quando o modelo é usado em contextos sensíveis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, o GPT é legal e tudo o mais... Mas e daí?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E daí que, graças ao modelo GPT, podemos ter um classificador de texto super calibrado para nos ajudar em nossas tarefas, sem o ônus de treinar tal modelo. E podemos utilizar o GPT a partir da API da OpenAI, de maneira muito simples! Outra vantagem que vale ressaltar é que, ao contrário de modelos tradicionais de classificação, podemos atribuir múltiplas categorias ao nosso texto.\n",
    "\n",
    "Vamos ver um exemplo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizando um catálogo de artigos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine o seguinte cenário: temos uma lista de todos os artigos que salvamos no site Medium. O problema desta lista é que o Medium não oferece nenhum tipo de categorização dos artigos. A única maneira de fazer isso é separando em várias listas, o que dificulta principalmente o processo de busca dos artigos. Além, é claro, de pressupor a classificação antes de ler o artigo.\n",
    "\n",
    "Essa tarefa realmente não é trivial, e seria muito útil poder fazer isso de forma automatizada. E o primeiro problema que temos é que nossa lista tem apenas o título e a url dos artigos. Para que a classificação seja mais precisa, precisamos de pelo menos algum texto que nos ajude a ter mais contexto a respeito do artigo.\n",
    "\n",
    "Então, vamos criar o nosso script classificador? Esse script vai executar as seguintes tarefas:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A[Carregar Lista de Arquivos] --> B\n",
    "  B[Buscar Título e Resumo<br>dos Artigos] --> C\n",
    "  C[Classificar Artigos] --> D[Salvar Lista de Artigos]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializando o ambiente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar as seguintes bibliotecas:\n",
    "- beautifulsoup4 - biblioteca para extrair a informação do HTML que contém a lista de artigos\n",
    "- openai - biblioteca para utilizar a API da openAI\n",
    "- requests - bibliotea para buscar informações da internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import bs4\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from requests_html import HTMLSession # importando o objeto de sessão do html requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa é carregar variáveis de ambiente. Lembrando que é necessário ter uma API key para usar a API da OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos carregar nossa lista de artigos, que está em um arquivo HTML, que podemos baixar lá no site do Medium. Vamos criar uma função, de forma que poderemos re-utilizar essa parte da rotina sempre que for necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_lista(nomearquivo: str):\n",
    "  html_artigos = bs4.BeautifulSoup(open(nomearquivo, \"r\"))\n",
    "  list_artigos = html_artigos.find_all(\"li\")\n",
    "\n",
    "  artigos = []\n",
    "  for item in list_artigos:\n",
    "    record = {}\n",
    "    record = {\n",
    "        \"titulo\": item.a.text,\n",
    "        \"link\": item.a[\"href\"],\n",
    "        \"autores\": None,\n",
    "        \"resumo\": None,\n",
    "        \"categorias\": None\n",
    "    }\n",
    "    artigos.append(record)\n",
    "  return artigos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código define uma função chamada \"retorna_lista\" que recebe um único parâmetro chamado \"nomearquivo\" do tipo string. A função primeiro abre o arquivo especificado pela string \"nomearquivo\" usando a função \"open\", lê o conteúdo e usa o método \"find_all\" do Beautiful Soup para procurar todos os elementos de lista no documento HTML e armazená-los na variável \"list_artigos\". A função, então, inicializa uma lista vazia chamada \"artigos\". Em um loop, ela itera sobre cada item da lista na variável \"list_artigos\" e cria um dicionário chamado \"record\" com três chaves: \"titulo\", \"link\", \"autores\", \"resumo\" e \"categorias\". Os valores para \"titulo\" e \"link\" são extraídos do texto da tag \"a\" e do atributo \"href\", respectivamente. O valor das chaves \"autores\", \"resumo\" e \"categorias\" são uma string vazia. O dicionário \"record\" completo é então adicionado à lista \"artigos\". Depois que todos os itens da lista são processados, a função retorna a lista \"artigos\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, podemos utilizar essa função conforme abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Número de Artigos: 1865.\n"
     ]
    }
   ],
   "source": [
    "artigos = retorna_lista(\"reading-list-medium.html\")\n",
    "\n",
    "print(f\" Número de Artigos: {len(artigos)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como ficou um registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n",
      "    \"link\": \"https://medium.com/p/e323b2d24987\",\n",
      "    \"autores\": null,\n",
      "    \"resumo\": null,\n",
      "    \"categorias\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(artigos[0], indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito! Estamos com os artigos preparados para buscarmos os dados extra que nos darão mais contexto para a categorização.\n",
    "\n",
    "Para fazer isso, vamos utilizar a biblioteca requests-html. Novamente, criaremos uma função para reutilizar depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_campos(registro: dict):\n",
    "    # Declaramos variaveis que contem seletores HTML\n",
    "    # Esses seletores nos ajudarão a encontrar os elementos HTML que contém o \n",
    "    # conteúdo referente ao autor, data publicação, titulo e lead\n",
    "    seletor_autor = [\n",
    "      \"#root > div > div > div:nth-child(3) > div > article > div > div > section > div > div:nth-child(3) > div > div > div:nth-child(2) > div > div > div > div > div > div > div > span > div > div > div > div > div > p > a\", \n",
    "      \"#root > div > div > div:nth-child(3) > div > article > div > div > section > div > div:nth-child(3) > div > div > div:nth-child(1) > div > div > div > div > div > div > div > span > div > div > div > div > div > p > a\", \n",
    "      \"#root > div > div > div:nth-child(2) > div > article > div > div > section > div > div:nth-child(2) > div > div > div > div > div > div > div > div > div > div > span > div > div > div > div > div > p > a\", \n",
    "      \"#root > div > div > div:nth-child(2) > div > article > div > div > section > div > div:nth-child(3) > div:nth-child(1) > div > div:nth-child(2) > div > div > div > div > div > div > div > span > div > div > div > div > div > p > a\"\n",
    "    ]\n",
    "    seletor_titulo_lead = [\n",
    "      \"#root > div > div > div:nth-child(3) > div > article > div > div > section > div > div:nth-child(3) > div > div > div:nth-child(2)\", \"#root > div > div > div:nth-child(2) > div > article > div > div > section > div > div:nth-child(3) > div:nth-child(1) > div > div:nth-child(2)\"\n",
    "    ]\n",
    "  \n",
    "    # Inicializamos o objeto HTMLSession para fazer a coleta da informação dos artigos\n",
    "    request = HTMLSession()\n",
    "    try:\n",
    "      print(registro[\"link\"])\n",
    "      conteudo_html = request.get(registro[\"link\"])\n",
    "      autor = \"Not available\"\n",
    "      \n",
    "      for item in seletor_autor:\n",
    "        aux_autor = None\n",
    "        aux_autor = conteudo_html.html.find(item, first=True)\n",
    "        if aux_autor is not None:\n",
    "          autor = aux_autor\n",
    "          break\n",
    "\n",
    "      head = \"Not available\"\n",
    "      for item in seletor_titulo_lead:\n",
    "        aux_head = None\n",
    "        aux_head = conteudo_html.html.find(item, first=True)\n",
    "        if aux_head:\n",
    "          aux_lead = aux_head.find('h2', first=True)\n",
    "          if aux_lead is not None:\n",
    "            head = aux_lead.text\n",
    "          \n",
    "      registro[\"autores\"] = autor.text\n",
    "      registro[\"resumo\"] = head\n",
    "        \n",
    "      return registro\n",
    "    except:\n",
    "      print('URL {0} com erro. Verifique.'.format(registro[\"link\"]))\n",
    "      return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `retorna_campos` faz o scraping de dados de páginas da web, especificamente páginas de notícias ou artigos de blog do Medium. Ele pega um dicionário de \"registro\" como entrada, que parece conter um \"link\" para uma página da web.\n",
    "\n",
    "Passo-a-Passo:\n",
    "\n",
    "1. Variáveis `seletor_autor` e `seletor_titulo_lead` são listas de seletores CSS. Seletores CSS são padrões usados para selecionar os elementos que você deseja estilizar. Aqui, eles são usados para identificar os elementos HTML onde as informações de autor e título/lead estão localizadas no HTML da página.\n",
    "\n",
    "2. A função então inicia uma sessão HTML usando o módulo `HTMLSession()` do pacote `requests_html`, que é uma biblioteca Python para fazer solicitações HTTP e para parsing de HTML.\n",
    "\n",
    "3. A função tenta fazer uma solicitação GET para a URL que está no campo \"link\" do dicionário de entrada.\n",
    "\n",
    "4. Em seguida, a função tenta encontrar o autor do artigo. Para isso, itera sobre a lista `seletor_autor` e, para cada seletor, tenta encontrar um elemento correspondente na página HTML. Se encontrar um autor, interrompe o loop e guarda o autor encontrado.\n",
    "\n",
    "5. Depois disso, a função tenta encontrar o título do artigo da mesma maneira, usando a lista `seletor_titulo_lead`.\n",
    "\n",
    "6. Os resultados são então adicionados ao dicionário de entrada no campo \"autores\" para o autor e \"resumo\" para o título.\n",
    "\n",
    "7. Se houver algum erro durante o processo, como um link quebrado ou se o seletor CSS não corresponder a nenhum elemento, a função exibe uma mensagem de erro e retorna None.\n",
    "\n",
    "8. Se tudo correr bem, a função retorna o dicionário de entrada, agora com informações adicionais sobre o autor e o resumo do artigo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos a execução da função para cada artigo em nossa lista. Observe que colocamos um limitador para fazer isso para 10 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/p/e323b2d24987\n",
      "https://medium.com/p/9e9536ebd839\n",
      "https://medium.com/p/bb7d31ed2e76\n",
      "https://medium.com/p/2688e319e2a5\n",
      "https://medium.com/p/7edae42a20b3\n",
      "https://medium.com/p/f87419cb14cb\n",
      "https://medium.com/p/d6169fc81204\n",
      "https://medium.com/p/74361bc3b92e\n",
      "https://medium.com/p/9dc1566d960d\n",
      "https://medium.com/p/3c053357c47f\n"
     ]
    }
   ],
   "source": [
    "artigos_comp = []\n",
    "i = 0\n",
    "for item in artigos:\n",
    "    artigos_comp.append(retorna_campos(item))\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os nossos artigos com título, autor e uma lead line, que vai nos ajudar no processo da categorização.\n",
    "\n",
    "Vamos agora, a nossa rotina de categorização, usando a API do OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_categorias(titulo, resumo):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=f\"We have these categories: dbt, Python, DataViz, Tableau, PowerBI, and Generative AI. Given those categories, please classify the following text with those categories: {titulo} - {resumo}. You can use only the categories listed. You can classify with multiple categories. If you think that none of the categories applies, you can tag as Other.\",\n",
    "        temperature=0.8,\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código define uma função chamada \"retorna_categorias\" que recebe dois parâmetros: \"titulo\" e \"resumo\". A função utiliza a API OpenAI para classificar o título e o resumo com base em um conjunto de categorias previamente determinadas - dbt, Python, DataViz, Tableau, PowerBI e Generative AI. Em seguida, retorna o resultado da classificação como uma string.\n",
    "\n",
    "A função retorna então a primeira (e única) escolha da resposta da API OpenAI, que é a string que representa a categoria que foi escolhida como a melhor correspondência para o texto de entrada. O método strip() é usado para remover qualquer espaço em branco inicial ou final da string retornada.\n",
    "\n",
    "Observação: Para usar este código, o módulo openai precisa ser importado e uma chave de API OpenAI precisa ser obtida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_final = []\n",
    "for item in artigos_comp:\n",
    "  item[\"categorias\"] = retorna_categorias(item['titulo'], item['resumo'])\n",
    "  lista_final.append(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que executamos a rotina acima, podemos imprimir os três primeiros registros e verificar que agora, temos categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n",
      "    \"link\": \"https://medium.com/p/e323b2d24987\",\n",
      "    \"autores\": \"John Loewen\",\n",
      "    \"resumo\": \"I\\u2019ve done the prompt engineering research so you don\\u2019t have to\",\n",
      "    \"categorias\": \"Python, Generative AI\"\n",
      "}\n",
      "{\n",
      "    \"titulo\": \"Power BI: How I Started Using Python To Automate Tasks\",\n",
      "    \"link\": \"https://medium.com/p/9e9536ebd839\",\n",
      "    \"autores\": \"Gabe Araujo, M.Sc.\",\n",
      "    \"resumo\": \"Not available\",\n",
      "    \"categorias\": \"PowerBI, Python\"\n",
      "}\n",
      "{\n",
      "    \"titulo\": \"Chat with your databases using LangChain\",\n",
      "    \"link\": \"https://medium.com/p/bb7d31ed2e76\",\n",
      "    \"autores\": \"Vishnu Sivan\",\n",
      "    \"resumo\": \"Not available\",\n",
      "    \"categorias\": \"Other\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(lista_final):\n",
    "    print(json.dumps(item, indent=4))\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aí estão os nossos artigos, devidamente categorizados. Inclusive, podemos ver um artigo que foi classificado como \"Other\", indicando que o texto que foi enviado não foi suficiente para classificar com as categorias selecionadas. \n",
    "\n",
    "Obrigado por ler até aqui! Espero que este script seja útil para vocês!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links Úteis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Understanding GPT-3: OpenAI's Language Generation AI: Blog oficial da OpenAI sobre GPT-3](https://www.openai.com/blog/gpt-3/) - Apresenta uma explicação detalhada do GPT-3 e seu uso potencial\n",
    "2. [Data Classification in Machine Learning](https://www.geeksforgeeks.org/ml-data-classification/) - Este é um artigo do site GeeksforGeeks que explica o conceito básico de classificação de dados em aprendizado de máquina, os diferentes tipos de algoritmos de classificação e como eles funcionam.\n",
    "3. Bibliotecas Python utilizadas no artigo:\n",
    "   1. [requests-html](https://requests.readthedocs.io/projects/requests-html/en/latest/)\n",
    "   2. [openai](https://platform.openai.com/docs/api-reference)\n",
    "   3. [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
